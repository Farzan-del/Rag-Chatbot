to run the code you must make the following folder struture for which you need to copy raw file and paste in notepad first. It will make you clear with the folder structure. Make folder structure like that and download all the libraries from requirements.txt file and then run this project.



RAG_Project/ â”‚ â”œâ”€â”€ requirements.txt # Python dependencies â”œâ”€â”€ README.md # Project documentation â”‚ â”œâ”€â”€ App/ # Core backend logic â”‚ â”œâ”€â”€ api_main.py # FastAPI main backend entry point â”‚ â”œâ”€â”€ pdf2img.py # Convert PDF to images using PyMuPDF â”‚ â”œâ”€â”€ ocr_tesseract.py # Perform OCR on images using Tesseract â”‚ â”œâ”€â”€ base64_utils.py # Encode/decode PDFs as Base64 â”‚ â”œâ”€â”€ chunker.py # Chunk extracted text â”‚ â”œâ”€â”€ embed_store.py # Generate embeddings & store in ChromaDB â”‚ â”œâ”€â”€ retriever.py # Retrieve top-k chunks for query â”‚ â”œâ”€â”€ llm_generator.py # Generate answers using Google Gemini API â”‚ â”œâ”€â”€ web_search.py # Web search fallback â”‚ â”œâ”€â”€ text_to_speech.py # Convert text answer to MP3 â”‚ â”œâ”€â”€ streamlit_app/ # Frontend â”‚ â”œâ”€â”€ app.py # Streamlit app for UI â”‚ â”œâ”€â”€ Data/ # Data storage folder â”‚ â”œâ”€â”€ Input_pdf_folder/ # Uploaded PDFs â”‚ â”œâ”€â”€ Extracted_texts/ # Extracted text files â”‚ â”œâ”€â”€ Chunks/ # Chunked text files â”‚ â”œâ”€â”€ Images/ # Converted PDF pages as images â”‚ â”œâ”€â”€ Audio/ # Generated speech MP3 files â”‚ â”œâ”€â”€ vector_db/ # Vector Database for RAG â”‚ â”œâ”€â”€ chroma_db/ # ChromaDB storage for embeddings â”‚ â””â”€â”€ .venv/ # Virtual environment (optional)

ðŸ“š RAG-Powered Chatbot with Voice
This project is an AI-powered Retrieval-Augmented Generation (RAG) chatbot that enables users to upload PDFs, extract text, and query the content intelligently. It leverages OCR for scanned PDFs, vector embeddings for document search, and an advanced LLM (Google Gemini) for generating precise, context-aware answers. If the relevant answer is not found in the uploaded document, the system optionally performs a web search to enrich responses, ensuring maximum accuracy.

Key features include:
âœ” PDF Upload & Processing â€“ Converts PDFs into images using PyMuPDF, extracts text with Tesseract OCR, and stores it in a structured format.
âœ” Text Chunking & Vector Storage â€“ Splits extracted text into manageable chunks and stores embeddings in ChromaDB for efficient semantic search.
âœ” Contextual Query Handling â€“ Answers questions by retrieving relevant text from the document; falls back to web search only if necessary.
âœ” Generative AI Response â€“ Uses Google Gemini API to generate human-like answers based on retrieved document context.
âœ” Voice Integration â€“ Converts answers into speech using gTTS, providing an audio playback option directly in the Streamlit UI.
âœ” Interactive Frontend â€“ Built with Streamlit, featuring an intuitive PDF upload sidebar, real-time Q&A chat interface, and embedded audio controls for listening to responses.

This solution is designed for students, researchers, and professionals who need an efficient way to extract knowledge from documents and interact with them conversationally. It blends information retrieval, generative AI, and speech synthesis to create a powerful, user-friendly tool for document-based Q&A.

Tech Stack:

Backend: FastAPI, PyMuPDF, Tesseract OCR, ChromaDB, Sentence Transformers
AI Model: Google Gemini API
Frontend: Streamlit
Voice: gTTS for Text-to-Speech
Other Tools: Requests, Uvicorn, Web Search APIs

Requirements
See the requirements.txt file and run:
pip install -r requirements.txt

Project Workflow
Upload PDF
â†’ Save & decode PDF â†’ Convert PDF pages into images.

Text Extraction
â†’ Apply Tesseract OCR to extract text.

Chunking & Embedding
â†’ Split text into chunks â†’ Create embeddings â†’ Store in ChromaDB.

Query Processing
â†’ User asks question â†’ Retrieve top chunks using semantic search.

Answer Generation
â†’ Generate response using Google Gemini API.

Fallback (Optional)
â†’ If PDF answer not found â†’ Search the web â†’ Regenerate answer.

Voice Output
â†’ Convert response to speech (MP3) using gTTS â†’ Stream audio in UI.

to run the code you must make the following folder struture
RAG_Project/
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ README.md                    # Project documentation
â”‚
â”œâ”€â”€ App/                         # Core backend logic
â”‚   â”œâ”€â”€ api_main.py              # FastAPI main backend entry point
â”‚   â”œâ”€â”€ pdf2img.py               # Convert PDF to images using PyMuPDF
â”‚   â”œâ”€â”€ ocr_tesseract.py         # Perform OCR on images using Tesseract
â”‚   â”œâ”€â”€ base64_utils.py          # Encode/decode PDFs as Base64
â”‚   â”œâ”€â”€ chunker.py               # Chunk extracted text
â”‚   â”œâ”€â”€ embed_store.py           # Generate embeddings & store in ChromaDB
â”‚   â”œâ”€â”€ retriever.py             # Retrieve top-k chunks for query
â”‚   â”œâ”€â”€ llm_generator.py         # Generate answers using Google Gemini API
â”‚   â”œâ”€â”€ web_search.py            # Web search fallback
â”‚   â”œâ”€â”€ text_to_speech.py        # Convert text answer to MP3
â”‚
â”œâ”€â”€ streamlit_app/               # Frontend
â”‚   â”œâ”€â”€ app.py                   # Streamlit app for UI
â”‚
â”œâ”€â”€ Data/                        # Data storage folder
â”‚   â”œâ”€â”€ Input_pdf_folder/        # Uploaded PDFs
â”‚   â”œâ”€â”€ Extracted_texts/         # Extracted text files
â”‚   â”œâ”€â”€ Chunks/                  # Chunked text files
â”‚   â”œâ”€â”€ Images/                  # Converted PDF pages as images
â”‚   â”œâ”€â”€ Audio/                   # Generated speech MP3 files
â”‚
â”œâ”€â”€ vector_db/                   # Vector Database for RAG
â”‚   â”œâ”€â”€ chroma_db/               # ChromaDB storage for embeddings
â”‚
â””â”€â”€ .venv/                       # Virtual environment (optional)
